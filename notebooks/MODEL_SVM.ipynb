{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo SVM para predecir la presión (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from typing import Union, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importar los clasificadores y escaladores necesarios\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler\n",
    "\n",
    "# Importar GridSearchCV para realizar la búsqueda de hiperparámetros\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir función para buscar hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la función que toma datos y devuelve los mejores parámetros\n",
    "\n",
    "def search_params(\n",
    "        estimator: BaseEstimator,\n",
    "        params: dict,\n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        random: bool = False, \n",
    "        n_iter: int = 100,\n",
    "    ) -> Tuple[SVR, dict]:\n",
    "    # Definir los parámetros para GridSearchCV\n",
    "\n",
    "    print(f\"Los parámetros para probar en nuestras pipelines son:\")\n",
    "    pprint(params)\n",
    "\n",
    "    # Creamos un pipeline con parámetros por defecto (serán sustituidos)\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', None),\n",
    "        ('regressor', estimator())\n",
    "    ])\n",
    "\n",
    "    if random:\n",
    "        search = RandomizedSearchCV(pipeline, params, cv=5, n_jobs=-1, \n",
    "                                    scoring='neg_mean_squared_error', verbose=1, n_iter=n_iter)\n",
    "    else:\n",
    "        search = GridSearchCV(pipeline, params, cv=5, n_jobs=-1, \n",
    "                              scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "    search.fit(X, y)\n",
    "\n",
    "    # Obtener los mejores hiperparámetros y el mejor modelo\n",
    "    best_params = search.best_params_\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(f\"Los mejores parámetros de la busqueda: {best_params}\")\n",
    "    print(f\"El mejor modelo de la busqueda: {best_model}\")\n",
    "\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../data/processed/datos_molienda_prueba.parquet'),\n",
      " PosixPath('../data/processed/df_model_no_outliers.parquet'),\n",
      " PosixPath('../data/processed/df_model_tidy.parquet')]\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta de los datos\n",
    "data_path: Path = Path(r\"../data/processed\")\n",
    "if not data_path.exists():\n",
    "    print(f\"El path {data_path} no existe, favor de revisar.\")\n",
    "\n",
    "# Imprimir archivos en la carpeta de datos\n",
    "pprint(list(data_path.glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>velocidad</th>\n",
       "      <th>potencia</th>\n",
       "      <th>rendimiento</th>\n",
       "      <th>ruido</th>\n",
       "      <th>p80</th>\n",
       "      <th>f80</th>\n",
       "      <th>per_solidos</th>\n",
       "      <th>wi</th>\n",
       "      <th>spi</th>\n",
       "      <th>imp_criticos</th>\n",
       "      <th>imp_estandares</th>\n",
       "      <th>jb</th>\n",
       "      <th>presion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-15 00:07:50</td>\n",
       "      <td>75.761029</td>\n",
       "      <td>39281.348296</td>\n",
       "      <td>65.653747</td>\n",
       "      <td>22.932414</td>\n",
       "      <td>64.260113</td>\n",
       "      <td>36.574719</td>\n",
       "      <td>71.583049</td>\n",
       "      <td>94.815049</td>\n",
       "      <td>54.50695</td>\n",
       "      <td>7.101110</td>\n",
       "      <td>65.598165</td>\n",
       "      <td>9.183127</td>\n",
       "      <td>87.199926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-15 00:08:00</td>\n",
       "      <td>75.761029</td>\n",
       "      <td>39850.320731</td>\n",
       "      <td>65.691489</td>\n",
       "      <td>22.932414</td>\n",
       "      <td>64.260113</td>\n",
       "      <td>36.555098</td>\n",
       "      <td>71.579590</td>\n",
       "      <td>94.815049</td>\n",
       "      <td>54.50695</td>\n",
       "      <td>7.191338</td>\n",
       "      <td>65.798205</td>\n",
       "      <td>9.180693</td>\n",
       "      <td>87.402467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-15 00:08:10</td>\n",
       "      <td>75.761029</td>\n",
       "      <td>39761.319456</td>\n",
       "      <td>65.783858</td>\n",
       "      <td>21.329909</td>\n",
       "      <td>64.260113</td>\n",
       "      <td>36.535478</td>\n",
       "      <td>71.585002</td>\n",
       "      <td>94.815049</td>\n",
       "      <td>54.50695</td>\n",
       "      <td>7.281566</td>\n",
       "      <td>65.998244</td>\n",
       "      <td>9.178803</td>\n",
       "      <td>87.492231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  velocidad      potencia  rendimiento      ruido  \\\n",
       "0 2022-11-15 00:07:50  75.761029  39281.348296    65.653747  22.932414   \n",
       "1 2022-11-15 00:08:00  75.761029  39850.320731    65.691489  22.932414   \n",
       "2 2022-11-15 00:08:10  75.761029  39761.319456    65.783858  21.329909   \n",
       "\n",
       "         p80        f80  per_solidos         wi       spi  imp_criticos  \\\n",
       "0  64.260113  36.574719    71.583049  94.815049  54.50695      7.101110   \n",
       "1  64.260113  36.555098    71.579590  94.815049  54.50695      7.191338   \n",
       "2  64.260113  36.535478    71.585002  94.815049  54.50695      7.281566   \n",
       "\n",
       "   imp_estandares        jb    presion  \n",
       "0       65.598165  9.183127  87.199926  \n",
       "1       65.798205  9.180693  87.402467  \n",
       "2       65.998244  9.178803  87.492231  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_path = data_path / \"df_model_tidy.parquet\"\n",
    "\n",
    "df = pd.read_parquet(parquet_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir `X` y `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X) = <class 'numpy.ndarray'>\n",
      "type(y) = <class 'numpy.ndarray'>\n",
      "X.shape = (248618, 12)\n",
      "y.shape = (248618,)\n"
     ]
    }
   ],
   "source": [
    "X: np.ndarray = df.drop(columns=[\"presion\", \"date\"]).to_numpy()\n",
    "y: np.ndarray = df[\"presion\"].to_numpy()\n",
    "\n",
    "# Verificar tipos\n",
    "print(f\"{type(X) = }\")\n",
    "print(f\"{type(y) = }\")\n",
    "\n",
    "# Verificar formas\n",
    "print(f\"{X.shape = }\")\n",
    "print(f\"{y.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservar una pequeña parte para probar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se usarán 24,861 entradas para el entrenamiento del modelo usando 5 folds)\n",
      "Se reservó un 10% de los datos (24,862) para validar al final del entrenamiento.\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "# Ya que el entrenamiento es muy tardado, tomemos solo una parte de los datos\n",
    "train_size = 0.10\n",
    "X_train_tune, _, y_train_tune, _ = train_test_split(X, y, train_size=train_size)\n",
    "\n",
    "print(f\"Se usarán {X_train_tune.shape[0]:,} entradas para el entrenamiento del modelo usando 5 folds)\")\n",
    "print(f\"Se reservó un {int(test_size*100)}% de los datos ({X_test.shape[0]:,}) para validar al final del entrenamiento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscar hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parámetros para probar en nuestras pipelines son:\n",
      "[{'regressor__C': array([  1.,  12.,  23.,  34.,  45.,  56.,  67.,  78.,  89., 100.]),\n",
      "  'regressor__gamma': ['scale', 'auto'],\n",
      "  'regressor__kernel': ['linear', 'rbf', 'poly'],\n",
      "  'scaler': [Normalizer(), StandardScaler(), MinMaxScaler()]}]\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores parámetros de la busqueda: {'scaler': MinMaxScaler(), 'regressor__kernel': 'poly', 'regressor__gamma': 'auto', 'regressor__C': 45.0}\n",
      "El mejor modelo de la busqueda: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('regressor', SVR(C=45.0, gamma='auto', kernel='poly'))])\n"
     ]
    }
   ],
   "source": [
    "# NOTA: para los parámetros del regresor se utiliza el prefijo regressor__ por convención\n",
    "# para indicar que ese parámetro es para el valor de la clave 'regressor'\n",
    "parameters = [\n",
    "    {\n",
    "        'scaler': [Normalizer(), StandardScaler(), MinMaxScaler()],\n",
    "        # Parámetros del clasificador\n",
    "        'regressor__C': np.linspace(1, 100, 10),\n",
    "        'regressor__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'regressor__gamma': ['scale', 'auto'],\n",
    "    },\n",
    "]\n",
    "\n",
    "best_model, best_params = search_params(\n",
    "    SVR, parameters, X_train_tune, y_train_tune, n_iter=1, random=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'coef0', 'degree', 'epsilon', 'gamma', 'kernel', 'max_iter', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.722488668671342\n",
      "Test set score: 0.7249967510527712\n"
     ]
    }
   ],
   "source": [
    "print('Training set score: ' + str(best_model.score(X_train, y_train)))\n",
    "print('Test set score: ' + str(best_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en ../models/best_svr.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el mejor modelo en un archivo\n",
    "model_filename = '../models/best_svr.pkl'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Modelo guardado en {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('regressor', SVR(C=45.0, gamma='auto', kernel='poly'))])\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo desde el archivo\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(f\"Modelo cargado: {loaded_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
